
Die Vermessung des Körpers mit dem ZOZOSUIT Studienarbeit des
Studiengangs Informatik an der Dualen Hochschule BadenWürttemberg
Stuttgart von Christoph Böhringer, Tobias Krämer 14.06.2021
Matrikelnummer, Kurs: 3275565, , TINF18IN Betreuer: Martin Kissel

Erklärung Wir versicheren hiermit, dass wir unsere Studienarbeit mit dem
Thema „Die Vermessung des Körpers mit dem ZOZOSUIT“ selbstständig
verfasst und keine anderen als die angegebenen Quellen und Hilfsmittel
benutzt habe. Wir versicheren zudem, dass die eingereichte elektronische
Fassung mit der gedruckten Fassung übereinstimmt. Falls gleichwertige
Entscheidungen getroen werden mussten, wurden diese von uns entschieden,
außer es ist anders angegeben. Ort Datum Christoph Böhringer, Tobias
Krämer I

Abstract This project describes the ZOZOSUIT and develops an app that
allows users to take one picture of their body and receive a 3Dmodel
according to their picture. This replicates the original app created by
ZOZO inc. in 2018. To accomplish this a mobile app using Flutter is
developed along with a server that receives the picture and extracts
measurement points. These points are then used to create the model. The
server returns the model to the app, which then renders and displays it.
II

Inhaltsverzeichnis Abstract II Abbildungsverzeichnis V
Tabellenverzeichnis VI Abkürzungen VII Glossar VIII 1 Einleitung 1 2
ZOZO 2 2.1 Das Unternehmen ZOZO 2 2.2 Der ZOZOSUIT 3 2.3 ZOZOSUIT 2 4 3
Stand der Technik 6 3.1 Frontend 6 4 Punkteverarbeitung 9 4.1 STAR 9 III

4.1.1 Shape 10 4.1.2 Pose 11 4.1.3 Funktionsweise 12 4.2 Verarbeiung 14
4.2.1 Idee 14 4.2.2 Umsetzung 15 4.2.3 Probleme 16 5 App 20 5.1 Aufbau
20 5.2 MainScreen 21 5.3 SelectBodyTypeScreen 23 5.4 TakePictureScreen
24 5.5 DisplayPictureScreen 25 5.6 ViewModelScreen 27 5.7 Probleme 28
5.7.1 iOS 28 5.7.2 Serverkommunikation 28 5.7.3 Model Viewer 29 6
Zusammenfassung und Ausblick 30

Abbildungsverzeichnis 2.1 Der ZOZOSUIT, Bildquelle: [ 3 ] 3 2.2
Bildquelle: [ 6 ], [ 7 ] 4 4.1 Gerenderte Modelle mit verschiedenen
ShapeParametern 10 4.2 Gelenke des STARModells (a) und
AxisAngleDarstellung einer Rotation [ 18 ] (b) 11 4.3 Gerenderte Modelle
mit verschiedenen PoseParametern 12 4.4 Vergleich von Joints des
StarModells und Punkten des Zozosuits mit IDs in Gelb 15 4.5 Vergleich
von Joints des StarModells und Punkten des Zozosuits mit IDs in gelb 17
5.1 Programmablauf der App 20 5.2 Der Mainscreen der App 21 5.3
ErrorMessage 22 5.4 Auswahl des Körpertyps 23 5.5 Aufnehmen eines Bildes
24 5.6 Anzeigen des aufgenommenen Bildes 25 5.7 Anzeigen des 3DModells
27 V

Tabellenverzeichnis VI

Abkürzungen API Application Programming Interface OS Operating System
SDK Software Development Kit UI User Interface VII

Glossar VIII

Kapitel 1 Einleitung Die ZOZOSUIT ist ein Ganzkörperanzug mit
gleichmäßig verteilten Punkten. Mit diesem Anzug und einer dazugehörigen
App können Nutzer, nach Aufnehmen eines 360GradBildes, die Maße ihres
Körpers und ein entsprechendes 3DModell erhalten. Das Unternehmen ZOZO
inc., welches den Anzug auf den Markt brachte, stellte die Produktion
des ZOZOSUIT, sowie die App, kurz nach der veröentlichung wieder ein.
Diese Studienarbeit soll sich mit dem Entwurf einer App beschäftigen,
welche die Funktion der ZOZOSUIT repliziert. Es soll eine Anwendung
entwickelt werden, welche aus einem Foto einer Person im ZOZOSUIT ein
3DModell dieser Person generiert. 1

Kapitel 2 ZOZO 2.1 Das Unternehmen ZOZO ZOZO inc. ist ein japanisches
Unternehmen, welches von Yusaku Maezawa im Jahr 1998 unter dem Namen
„Start today“ gegründet wurdet. Damals verkaufte das Unternehmen
importierte CDs und Schallplatten. Das Unternehmen eröffnet im Jahr 2004
den OnlineShop ZOZOTOWN und stellt zwei Jahre später den verkauf
importierter CDs komplett ein. Im Lauf der Jahre wurde der OnlineSohp
immer weiter erweitert und weitere Unternehmen wurden in ZOZO inc.
aufgenommen. Im Jahr 2018 veröentlichte das Unternehmen den ZOZOSUIT.
Ein Anzug und eine dazugehörige App, mit welcher der eigene Körper
gemessen werden kann. Mithilfe dieser Daten konnten Nutzer
maßgeschneiderte Kleidung im OnlineShop bestellen. Heute hat das
Unternehmen 1297 Mitarbeiter und macht einen jährlichen Umsatz von 1,1
Billionen Dollar [ 1 ].[ 2 ] 2

2.2 Der ZOZOSUIT Abbildung 2.1: Der ZOZOSUIT, Bildquelle: [ 3 ] Der
ZOZOSUIT ist ein enger Ganzkörperanzug mit gleichmäßig verteilten
Punkten. Der Anzug wurde kostenlos an interessierte Menschen in der
gesamten Welt versendet. Zu dem Suit gehört eine App, mit welcher Nutzer
ein 360GradBild von sich selbst im ZOZOSUIT machen. Die App erkennt die
auf dem ZOZOSUIT angebrachten Punkte und berechnet daraus die Maße
des/der Trägers/in. Die berrechneten Maße können Nutzer hochladen und
mit diesen Kleidung bei ZOZO inc. bestellen. Das Unternehmen versprach
dabei, dass die bestellte Kleidung auf den Benutzer maßgeschneidert ist
und innerhalb von zwei Wochen weltweit geliefert wird. In der Realität
Betrug die Lieferzeit teils mehrere Monate. Zudem war die erhaltene
Kleidung nicht passgenau. Dies sorgte für Enttäuschung und Unverständnis
bei den Kunden, und als Resultat fiel der Wert von ZOZOAktien um circa
50% [ 4 ]. [ 5 ] In Japan wurde die Benutzung des ZOZOSUIT bereits Ende
2018 abgeschafft und das Unternehmen entschuldigte sich für die große
Enttäuschung. Allerdings konnten die von Nutzern hochgeladenen
Körperdaten weiterhin verwendet werden. Die Daten von millionen
verschiedenster Körpertypen konnte ZOZO inc. dazu verwenden, die
Produktion von nicht maßgeschneiderten Klamotten anzupassen. Somit 3

wurde die Passgenauigkeit der von ZOZO produzierten Klamotten für den
Durchschnitt der Bevölkerung erhöht. 2.3 ZOZOSUIT 2 (a) Der ZOZOSUIT 2
(b) Ausgewertete Punkte Abbildung 2.2: Bildquelle: [ 6 ], [ 7 ] Der
ZOZOSUIT 2 verspricht das gleiche wie der ZOZOSUIT: ein hautenger Anzug
mit gleichmäßigen Punkten und eine dazugehörige App, welche diese
auswertet und anschließend ein 3DModell des Körpers anzeigt. Der
ZOZOSUIT 2 besitzt im Vergleich zur ZOZOSUIT 50 mal mehr erkennbare
Punkte. Zudem sind, laut Angaben von ZOZO inc. die zur Auswertung
verwendeten Algorythmen verbessert worden. Zudem ist der Abstand der
Punkte, welche zur Identifizierung der eigentlichen Messpunkte benötigt
werden, von 0,2mm auf 0,4mm erhöht worden. Dies 4

soll ermöglichen, dass Smartphones die Punkte besser erkennen. [ 8 ] Wie
sich im Verlauf dieser Studienarbeit herausstellt, würde die ZOZOSUIT 2
einige Probleme der PunkteErkennung und Verarbeitung lösen (vgl. 4.2.3
). 5

Kapitel 3 Stand der Technik 3.1 Frontend In dieser Studienarbeit sollen
Bilder von einer Person im ZOZOSUIT gemacht werden und diese
anschließend ausgewertet und als 3DModell dargestellt werden. Da sowohl
Bilder gemacht, als auch Grafiken angezeigt werden, bietet sich das
Smartphone als Frontend an. In Deutschland besitzen 81% der Bevökerung
ab 14 Jahren ein Smartphone, in jungen Altersgruppen steigt der
Prozentsatz auf über 95% [ 9 ]. Smartphones können innerhalb weniger
Sekunden aus der Tasche geholt und gestartet werden, dies ermöglicht
einen schnellen Gesprächseinstieg mit Strike Up. Für Smartphones
bestehen zwei dominante Betriebssysteme: Android und i OS . Mit einem
Marktanteil von 69,8% ist Android in Deutschland Marktführer für
Smartphonebetriebssysteme, gefolgt von i OS mit 29,8%. Andere
Betriebssysteme, wie Windows und Blackberry, besitzen einen Marktanteil
von 0,4%. [ 10 ]. Für Android entwickelte Apps basieren auf Java oder
Kotlin, während i OS Apps in Swift oder ObjectiveC entwickelt werden.
Des weiteren gibt es Tools und Software Development Kits(SDK) , mit
welchen Apps entwickelt werden können, welche mit wenigen
Einschränkungen auf beiden Betriebssystemen lauähig sind: • React
Native: React Native ist ein JavaScript Framework, welches die UI in 6

native (Android oder iOS spezifische) Elemente umwandelt. Die Logik
bleibt dabei unverändert. Das Framework wird von Facebook, Instagram und
Uber benutzt. • Xamarin: Xamarin ermöglicht es Entwicklern eine
gemeinsame Logik für Android und iOS zu schreiben. Die jeweilige UI wird
allerdings in einer nativen Programmiersprache entwickelt. • Flutter:
Flutter ist ein SDK , welches von Goolge erstellt, und im Jahr 2018
erstmals in der Version 1.0 veröentlicht wurde. Das SDK verwendet die,
ebenso von Google entwickelte, Programmiersprache Dart. Flutter
ermöglicht es UIKomponenten zu entwickeln, welche auf beiden
Betriebssystemen konsistent sind. Damit Apps im App Store von Apple
veröentlicht werden dürfen, benötigt der/die Entwickler/in eine
Mitgliedschaft im Apple Developer Program. Diese kostet pro Jahr 99
USDollar [ 11 ]. Des Weiteren kann eine für i OS entwickelte Anwendung
nur in einer AppleUmgebung (Macbook, …) kompiliert werden. Aus diesen
Gründen, und wegen dem Verbreitungsanteil von 29,8% in Deutschland, ist
das Entwickeln dieser App für eine reine i OS Umgebung nicht sinnvoll.
Um Apps im Google Play Store zu veröentlichen, wird eine einmalige
Registrierungsgebühr von 25 USDollar benötigt [ 12 ]. Eine jährliche
Gebühr ist nicht vorhanden. React Native ermöglicht zwar das Entwickeln
einer Anwendung für iOS und Android, jedoch werden nicht alle
plattformspezifischen Application Programming Interfaces (APIs)
unterstützt. Nicht unterstützte APIs müssen in der nativen
Programmiersprache erstellt werden. Es muss somit trotzdem für iOS und
Android separat entwickelt werden. [ 13 ] Die nicht vollständige
Unterstützung nativer APIs ist eine Schwachpunkt aller Frameworks,
welche das gleichzeitige Entwickeln für iOS und Android ermöglichen.
Xamarin bietet durch die Unterstützung von .Net und Microsoft Visual
Studio die beste Entwicklungsumgebung. Jedoch mindert die geringe
Popularität die Verfügbaren Hilfestellungen durch andere
Entwickler/innen [ 14 ]. Laut einer Umfrage von Stack Overflow ist
Flutter das beliebteste der drei vorgestellten Frameworks [ 15 ]. Es ist
jedoch auch das jüngste (Version 1.0 im Jahr 2018) und kann 7

somit auf den geringsten Anteil an verfügbaren Hilfestellungen
zurückgreifen. Auch die Unterstützung durch Bibliotheken von Dritten ist
noch nicht so ausgererift, wie bei den anderen Frameworks. Allerdings
steht eine gute OnlineDokumentation zur Verfügung, welche unter [ 16 ]
erreichbar ist. [ 14 ] Ein weiterer negativer Aspekt der
CrossPlatformEntwicklung sind Systemupdates von iOS oder Android. Ein
Systemupdate kann neue Funktionen hinzufügen und alte Verändern oder
Entfernen. Während bei nativen Plattformen darauf geachtet wird, dass
alle Änderungen rückwärtskompatibel sind, müssen sich
CrossPlatformFrameworks erst an die Änderungen anpassen. Dadurch kann es
während Übergangsphasen zu fehlerhaftem Verhalten der App kommen. In
Anbetracht dieser Punkte ist das Entwickeln des Frontends als reine
AndroidApp oder als plattformübergreifende App unter Verwendung eines
Frameworks denkbar. Die Wahl fällt hierbei auf eine CrossPlatformApp,
welche mithilfe von Flutter, und der damit verbundenen
Programmiersprache Dart, erstellt wird. Dies begründet sich darin, dass
bei einer reinen Android- Anwendung knapp ein Drittel der
Smartphonebesitzer keinen Zugriff auf die App haben würden. Die Wahl von
Flutter ergibt sich aus der guten OnlineDokumentation und der
Popularität, durch welche möglicherweise auftretende Probleme besser
gelöst werden können. Als Entwicklungsumgebung wird Android Studio
gewählt, da dieses ein FlutterPlugin besitzt und einen Emulator
bereitstellt, mit welchem verschieden Smartphones auf verschiedenen API
Stufen simuliert werden können. 8

Kapitel 4 Punkteverarbeitung 3DObjekte werden oft durch Scheitelpunkte
und Dreiecke dargestellt, welche deren dreidimensionale Form
widerspiegelt. Dabei gilt, je detaillierter ein Objekt ist, desto mehr
Scheitelpunkte werden benötigt. Bei einem Objekt wie dem Menschen mit
weitgehend vordefinierter Form kann die Darstellung jedoch auf einige
wenige Größen wie Höhe, Dicke, Brustumfang, Bauchgröße und Pose
reduziert werden. Diese Darstellung ist oft kleiner und
aussagekräftiger. [ 17 ] Die Idee ist die Entwicklung einer
Funktionalität, welche die Rückgabewerte der Messfunktion als
Eingangsparameter für die Erstellung eines Modells mit STAR nutzbar
macht. 4.1 STAR Eine dieser Darstellungen ist der Sparse Trained
Articulated Human Body Regressor (STAR). STAR ist ein statistisches
Modell, das den menschlichen Körper mit zwei Parametern, dem
ShapeParameter  für die Form und dem PoseParameter  für die Pose,
beschreibt. 9

4.1.1 Shape Einer der beiden Parameter für die Generierung des Modells
eines menschlichen Kröpers mit STAR ist der sogenannte ShapeParameter.
Dieser umfasst 10 bis 300 Skalare  =  0 ; : : : ; jj  , welche die
Form des menschlichen Körpers widerspiegeln. Jedes Skalar erwirkt bei
der Modellgenerierung eine Veränderung eines bestimmten Merkmals. Das
Skalar 0 ist dabei beispielsweise ausschlaggebend für die Größe des
Modells, 1 wirkt auf das Verhältnis von Körpergröße und Gewicht,
ähnlich wie der Body Mass Index. Der Wert für 2 bestimmt die Höhe des
Torsos und Schulterbreite, jener für 3 die Brustbreite sowie
Nackenhöhe. (a) negativ (b) positiv (c) default (=0) Abbildung 4.1:
Gerenderte Modelle mit verschiedenen ShapeParametern 10

Ein negativer Wert für ein Skalar reduziert dabei das entsprechende
Merkmal, ein positiver Wert verstärkt dieses (vgl. Abb. 4.1 ). Je höher
dabei die Anzahl an Skalaren, desto genauer lässt sich das Modell an
einen bestimmten Körperbau anpassen, im Gegenzug erhöht sich aber der
Rechenaufwand. 4.1.2 Pose Der zweite Eingabeparameter für STAR ist der
PoseParameter, welcher die zu generierende Pose mit 24 Vektoren  = 
~0 ; : : : ; ~23  , die je 3 Skalare ~n =  xn ; yn ; zn  umfassen,
beschreibt. Die Vektoren werden als Rotation in AxisAngleDarstellung von
Gelenken des menschlichen Körpers relativ zum Vorgängergelenk
interpretiert, welche zusammengesetzt einen sogenannten Kinematischen
Baum mit den wichtigsten Gelenkpunkten ergeben (vgl. Abb. 4.2 , (b)).
Die AxisAngleDarstellung beschreibt die Drehung eines dreidimensionalen
Objekts um den Winkel  um eine Rotationsachse mit dem Einheitsvektor ~e
. Diese beiden Variablen können mit   ~e als Vektor mit drei
Parametern und dem Betrag  zusammengefasst werden. (vgl. Abb. 4.2 ,
(a)). (a) (b) Abbildung 4.2: Gelenke des STARModells (a) und
AxisAngleDarstellung einer Rotation [ 18 ] (b) 11

Dabei gilt, je kleiner der Wert eines Skalars gegenüber den anderen
beiden Skalaren, desto geringer ist die Drehung entlang der
entsprechenden XAchse, YAchse oder ZAchse. Ein Drehung um  2 um die
XAchse und  2 um die YAchse entspräche  0:89   2 ; 0:45   2 ; 0 
in AxisAngleDarstellung. Durch verschiedene Gewichtungen der 24 Vektoren
kann so jede erdenkliche Pose dargestellt werden (vgl. Abb. 4.3 , (b)).
Sind die Elemente eines Vektors ~n =  0 ; 0 ; 0  , befindet sich das
Gelenk in Ruheposition. Abbildung 4.3 (a) zeigt das Modell, bei dem sich
alle Gelenke in Ruhepose befinden. (a) Ruhepose (b) Zufällige Pose
Abbildung 4.3: Gerenderte Modelle mit verschiedenen PoseParametern 4.1.3
Funktionsweise Die Pipeline der Synthese des menschlichen Körpers mit
Star erfolgt in drei Schritten. In einem ersten Schritt wird ein
TemplateModell T in Ruhepose und ohne FormKorrekturen erstellt und
Scheitelpunktversätze zum Modell T mit der Funktion Bs(; S) berechnet.
Der Parameter S beschreibt dabei vordefinierte grundlegende Komponenten,
welche den Bereich der menschlichen Formvariabilität erfassen. Addiert
ergeben Modell T und Scheitelpunktversätze ~Vshaped , ein Modell in
Ruhepose, das die mit den ShapeKoeffizienten definierten physikalischen
Attribute und die Identität widerspiegelt. 12

Der menschliche Körper verformt sich in unterschiedlichen Posen anders,
was für ein realistisches Ergebnis in Betracht gezogen werden muss.
Diese Verformung ist zudem abhängig von der Form des Körpers. Der zweite
Schritt dient dementsprechend der Berechnung der durch die Pose 
verursachten Verformungen in Korelation mit den ShapeKoeffizienten 
durch die Funktion Bp(~q; 1) . Der Parameter ~q stellt dabei den
kinematischen Baum als Quaternion mit je vier Parametern pro
Skelettpunkt dar. 1 , also der zweite Koezient des ShapeParameters, ist
repräsentativ für die allgemeine Form des Körpers und stimmt in vielen
Punkten mit dem Body Mass Index (BMI) überein. Da 1 den mit Abstand
größten Einfluss auf die Verformungen durch spezielle Posen hat, können
die restlichen ShapeKoeffizienten vernachlässigt werden. Das Endresultat
~Vposed , gegeben durch stellt nun ein Modell in Ruhepose dar, das
sowohl Verformungen durch den ShapeParameter als auch durch den
PoseParameter umfasst. Da das Modell ~Vposed posenspezifische
Verformungen umfasst, aber trotzdem in Ruhepose dargestellt wird, kann
ein leicht unförmiger Eindruck entstehen. Im dritten und letzten
Schritt, dem sogenannten Skinning, wird das Mesh mit einer standard
skinning Funktion W um die Joints von ~Vshaped transformiert sowie durch
ein erlerntes Set aus blend weight parametern geglättet. Das Modell ist
schlussendlich gegeben durch Die Funktion J regressiert dabei die Joints
zwischen den Skelettpunkten aus ~Vshaped . Das so synthetisierte Modell
des menschlichen Körpers ist realistisch und weicht bei richtiger
Messung und Parametrierung von Shape und Pose um nur wenige Millimeter
ab. Ziel des folgenden Kapitels ist die Entwicklung einer
Funktionalität, welche die Rückgabewerte der Messfunktion als
Eingangsparameter für die Erstellung eines Modells mit STAR nutzbar
macht. 13

4.2 Verarbeiung Um mittels Star ein realistisches Modell des
menschlichen Körpers zu generieren, müssen die Rückgabewerte der
MeasureFunktion zu ShapeParameter v und PoseParameter  konvertiert
werden. Im folgenden wird die Idee der Konvertierung, die Umsetzung
sowie aufgetretene Probleme dargestellt. 4.2.1 Idee In allen großen
Messpunkten des Zozosuits befindet sich eine einzigartige
Punkteanordnung, wodurch jedem gescannten Messpunkt eine ID und somit
eine entsprechende Position auf dem Zozosuit zugewiesen werden kann.
Diese ID wird von der MeasureFunktion, neben den genauen Koordinaten und
einer geschätzten Entfernung des Punktes, erfasst. Dadurch lässt sich
eine dreidimensionale Punktewolke erzeugen und die genauen Koordinaten
eines Messpunktes auf dem Zozosuit mit der ID ermitteln. Die Pose kann
so durch Zuweisung von passenden Punkten des Zozosuits zu den
Gelenkpunkten des PoseParameters rekonstruiert werden. Hierfür ist es
erforderlich, die Rotation In AxisAngleDarstellung zu berechnen, welche
den Vektor zwischen zwei Gelenkpunkten des kinematischen Baums der
Ruhepose zu dem Vektor zwischen den zwei entsprechenden Punkten auf dem
Zozosuit rotiert. Die Ermittlung des ShapeParameters erweist sich als
komplexer. Die bis zu 300 verschiedenen Skalare, welche auch in
gegenseitiger Wechselwirkung stehen, zu erschließen, ist mit den Daten,
die die Messfunktion des Zozosuit liefert, unmöglich. Allerdings könnte
man nur einige wenige der Skalare betrachten, welche einen großen
Einfluss auf die allgemeine Form haben, wie die Skalare 0 und 1 ,
welche die Größe sowie den Body Mass Index des Modells beschreiben.
Diese können durch Messung von Entfernungen verschiedener bestimmter
Punkte grob bestimmt werden. Dies soll aber im Rahmen der Arbeit dieser
Arbeit nicht näher betrachtet werden. 14

4.2.2 Umsetzung Für die Ermittlung der Pose aus den Daten der
ZozosuitMessfunktion erfolgt in einem ersten Schritt die Zuweisung der
IDs von Messpukten zu den Gelenkpunkten des PoseParameters. Dies wird
einmalig durch einen Vergleich von Gelenkpunkten des Kinematischen Baums
und Messpunkten auf dem Zozosuit ermittelt. (a) Erfasste Punkte (b)
Numerierte Joints des STARModells [ 19 ] Abbildung 4.4: Vergleich von
Joints des StarModells und Punkten des Zozosuits mit IDs in Gelb Die
Koordinaten der Messpunkte, deren ID mit einem Gelenkpunkt verknüpft
ist, werden aus dem Rückgabewert raw_data als dreidimensionale
Punktewolke ausgelesen. Da der PoseParameter Rotationen von Gelenk zu
übergeordnetem Gelenk gemäß des kinematischen Baums benötigt, ist eine
Konvertierung der Punktewolke zu Rotation in AxisAngleDarstellung
erforderlich. Die Rotation eines Gelenks wird dabei relativ zur 15

Rotation des Gelenks in Ruhepose berechnet. In anderen Worten muss die
Rotation des Vektors v_src von übergeordnetem Gelenkpunkt zu Gelenkpunkt
der Ruhepose zu Vektor v_dst von übergeordnetem Gelenkpunkt zu
Gelenkpunkt der Messpose berechnet werden. Hierfür dient die Funktion
axis_angle(v_src,v_dst), welche die Rotation von v_src zu v_dst in
AxisAngleDarstellung zurückgibt. In der Funktion axis_angle(…) werden in
einem ersten Schritt werden beide Vektoren genormt, da lediglich die
Richtung der Vektoren bei der Berechnung der Rotationsmatrix eine Rolle
spielen. Die Rotationsachse ist definiert durch das Kreuzprodukt von
Ursprungsvektor und Zielvektor, der Winkel der Drehung durch den
Arkustangens des Skalarprodukts der beiden Vektoren. Demnach lässt sich
die Drehung eines Vektors ~vsrc zu einem Vektor ~vdst in
AxisAngleDarstellung mit berechnen. Nachdem dies für alle Gelenke
berechnet wird, lässt sich mit Hilfe von Star ein Modell generieren,
welches die Pose der Person auf dem Bild widerspiegelt. Allerdings
treten dabei einige Probleme auf, die das Ergebnis stark verzerren
können, welche im folgenden vorgestellt werden. 4.2.3 Probleme Bei der
Synthese der Pose aus den Messpunkten des Zozosuit treten eine Reihe von
Problemen auf. Fehlende Messpunkte an Gelenken Eine Problem ist, dass
nicht für jedes Gelenk ein Messpunkt auf dem Zozosuit existiert. Einige
Gelenke müssen deshalb komplett ausgelassen werden, wie beispielsweise
jene an Kopf, Füßen und Händen, da kein Messpunkt in der Nähe existiert.
Diese sind für die gesamte Pose aber nicht ausschlaggebend. Deshalb wird
für diese die Ruhepose des Gelenkes  =  0 ; 0 ; 0  verwendet. Bei
anderen Gelenken, vor allem in der 16

Schulterregion liegen die Messpunkte lediglich in der Nähe des Gelenks
(vgl. Abb. 4.5 ). (a) Erfasste Punkte in der Schulterregion (b) Gelenke
in der Schulterregion [ 19 ] Abbildung 4.5: Vergleich von Joints des
StarModells und Punkten des Zozosuits mit IDs in gelb Dadurch wird die
Pose verzerrt, Beispiele hierfür sind leicht falsch abstehende Arme oder
gespreizte Beine. Zwar können einige Gelenke durch Zusammenspiel von
mehreren Messpunkten berechnet werden, allerdings wird der Eekt durch
das nachfolgend beschriebene Problem verstärkt. 17

Lückenhafte Punkterkennung Bei der Erkennung der Messpunkte mit der
ZozosuitMessfunktion werden häufig Punkte gar nicht oder ohne ID
erkannt. Die dadurch entstehende lückenhafte dreidimensionale
Punktewolke der Messpose hat zur Folge, dass nicht alle PoseParameter
berechenbar sind. Jeder fehlende Messpunkt, mit Ausnahme der Start- und
Endpunkte, verursacht zwei fehlende PoseParameter, die zur Ruhepose des
Gelenks gesetzt werden müssen. Dadurch kommt es teils zu einer Pose des
Modells, die einigen essentiellen Aspekten gar nicht mit der Pose des
Menschen auf dem Bild übereinstimmt. So kann eine fehlerhafte Erkennung
des Messpunktes für ein Schultergelenk dazu führen, dass der Arm des
Modells waagerecht (Ruhepose) steht, und nicht wie auf dem Bild
dargestellt. Wird versucht, Gelenke mit mehreren Messpunkten zu
beschreiben, steigt dabei die Wahrscheinlichkeit für fehlende
berechenbare PoseParameter, sodass dies keine Lösung zum ersten Problem
darstellt. Verzerrung durch Drehung des Zozosuits Ein weiteres Problem
ist, dass sich der Zozosuit nach dem Anziehen oft leicht verdreht ist.
Dadurch liegen die vordefinierten Messpunkte nicht genau auf den
entsprechenden Gelenken, oder können teils gar nicht erkannt werden, da
diese nun im toten Winkel der Kamera liegen. Dies verursacht häufig
gespreizte beziehungsweise verdrehte Beine oder einen verdrehten
Oberkörper sowie eine lückenhafte Erkennung der Punkte in der Armregion,
was eine Darstellung der Arme in Ruhepose zur Folge hat. Zwar kann diese
Fehlerquelle durch korrekten Sitz des Zozosuits teilweise verhindert
werden, allerdings verbleibt meistens eine Restdrehung. Fehlerhafte
Erkennung der ID Die wohl gravierendste Fehlerquelle besteht in der
falschen Erkennung der ID eines Messpunktes. Teilweise weist die
ZozosuitMessfunktion einem Messpunkt eine falsche ID zu. Ist der
Messpunkt jener falsch erkannten ID einem Gelenk zugewiesen, kann dies
gravierende Folgen für das generierte Modell haben. Je nach Lage des
Messpunktes mit 18

der falschen ID kann das Gelenkt stark verdreht werden, was eine
groteske Darstellung des Gelenks im Modell zur Folge hat. Das Modell
zeigt dadurch teilweise einen in Teilen deformierten menschlichen
Körper, beispielsweise mit einem grotesk verdrehten und abstehendem
Bein, was bei den vorgenannten Problemen nicht auftreten kann. Bei jenen
wird zwar die Pose oft nicht richtig widergespiegelt, allerdings
verkörpert die gezeigt Pose im Modell eine reale, nachstellbare Pose. 19

Kapitel 5 App Da die App Kamerafunktionen verwendet, wird auf dem
Smartphone ein API Level von 21 vorausgesetz. Dies entspricht Android
5.0, welches 2014 erschienen ist. 5.1 Aufbau Abbildung 5.1:
Programmablauf der App In 5.1 ist der Programmablauf der App
dargestellt. Die einzelnen Screens und deren Funktionen werden in den
folgenden Abschnitten erläutert. Da das Design kein Hauptmerkmal der
Anwendung ist, wurde eine simple Benutzeroberfläche erstellt. Diese
beruht auf einem DarkDesign und setzt Akzente in Blau. 20

5.2 MainScreen Abbildung 5.2: Der Mainscreen der App Der Startbildschirm
der Anwendung ( 5.2 ) verfügt über zwei Buttons: „Take picture“ und
„View previous model“. Mit „View previous model“ wird der
ViewModelScreen ( 5.7 ) aufgerufen und das zuletzt generierte 3DModell
angezeigt. Befindet sich auf dem Gerät kein zuvor generiertes Modell, so
wird ein Popup mit einer ErrorMessage angezeigt ( 5.3 ). Diese weißt
darauf hin, dass kein Modell vorhanden ist und dieses somit zuerst durch
Aufnehmen und Auswerten eines Fotos generiert werden muss. Sobald der
Startbildschirm generiert wird, werden die auf dem Smartphone
verfügbaren Kameras gescannt und in einer Liste gespeichert. Aus dieser
Liste wird die Rückkamera ausgelsesen und gespeichert. Die Kamera wird
später in 5.4 benötigt. Das Auslesen und Auswerten der Gerätekameras
kann etwas Zeit in Anspruch nehmen, weshalb dies bereits im Mainscreen
passiert und nicht erst beim Aufrufen von TakePictureScreen. Wird der
Button „Take picture“ gedrückt, so wird der SelectBodyTypeScreen
generiert und diesem die zuvor gespeicherte Kamera übergeben. 21

Abbildung 5.3: ErrorMessage 22

5.3 SelectBodyTypeScreen Abbildung 5.4: Auswahl des Körpertyps Auf dem
SelectBodyTypeScreen sind drei Buttons vorhanden: „Male“, „Use testing
image“ und „Female“. Zusätzlich ist eine Statusleiste vorhanden, welche
zurück zum vorherigen Screen leitet. Der Button „Use testing image“
leitet den Nutzer direkt zum DisplayPictureScreen ( 5.5 ). Dort wird ein
Beispielbild eines Entwicklers in der ZOZOSUIT angezeigt, welches
anschließend ausgewertet werden kann. Diese Funktion ist sinnvoll, wenn
man die Anwendung testen will und keinen eigenen ZOZOSUIT besitzt oder
wenn man den Prozess des An- und Ausziehens des ZOZOSUIT umgehen will.
Die Buttons „Male“ und „Female“ leiten den Nutzer zum TakePictureScreen
weiter. Hierbei wird die Variable gender übergeben, welche bei der
Generierung des 3DModells benötigt wird. Das drücken eines Buttons setzt
dabei die Variable auf das dem Button entsprechende Geschlecht. 23

5.4 TakePictureScreen Abbildung 5.5: Aufnehmen eines Bildes Der
TakePictureScreen verfügt über einen Button mit einem Kamerasymbol und
eine Statusleiste, welche den Nutzer zum vorherigen Screen leitet. In
der Mitte des Bildschirms wird der aktuelle Kamerafeed der Rückkamera
angezeigt, welche bereits in 5.2 bereitgestellt wurde. Wird der
Kamerabutton gedrückt, so wird ein Bild aufgenommen und temporär
gespeichert. Der Pfad zum aktuellen Bild und das vom
SelectBodyTypeScreen erhaltene Geschlecht werden an den
DisplayPictureScreen weitergeleitet, welcher nun generiert wird. 24

5.5 DisplayPictureScreen Abbildung 5.6: Anzeigen des aufgenommenen
Bildes Der DisplayPictureScreen zeigt das zuvor aufgenommene Bild an und
besitzt den Button „Evaluate“ und eine Statusleiste, welche den Nutzer
zum vorherigen Screen leitet. Wurde im SelectBodyTypeScreen der Button
„Use test image“ gedrückt, so wird eine Variante dieses Screens
angezeigt. Der einzige Unterschied liegt dabei darin, dass nicht das
zuvor aufgenommene Bild, sondern ein aus den, in der App enthaltenen,
Assets geladenes Bild, angezeigt wird. Wird der Button gedrückt, so
zeigt dieser eine Ladeanimation an, bis alle durch den Button
aufgerufenen Funktionen abgeschlossen sind. Zuerst wird das aktuelle
Bild zu einem Base64String ([ 20 ]) konvertiert. Der somit generierte
String wird nun mit dem erhaltenen Geschlecht JSONkodiert per
POSTRequest an den Server gesendet. Der Server wertet die Daten aus und
generiert daraus ein 3DModell als .glbDatei. Diese Datei wird zu Base64
kodiert und JSONkodiert an die App zurückgesendet. Der Base64String wird
nun dekodiert und in dem appspezifischen Speicher gespeichert. 25

Hierbei muss darauf geachtet werden, dass die Speicherorte auf Android
und iOS Geräten verschieden sind. Deshalb wird das Betriebssystem des
Smartphones bestimmt und daraus lässt sich der Pfad zum Speicherort für
appspezifische Dateien generieren. Die dekodierte Datei wird nun an dem
erhaltenen Pfad gespeichert. Der Pfad zum gespeicherten 3DModell (die
.glb Datei) wird gespeichert und an den ViewModelScreen weitergegeben,
welcher nun generiert wird. 26

5.6 ViewModelScreen Abbildung 5.7: Anzeigen des 3DModells Der
ViewModelScreen erhält einen Pfad zu einer .glbDatei. Diese Datei wird
gerendert und als drehbares 3DModell gerendert. Zusätzlich ist eine
Statusleiste mit einem HomeButton vorhanden, welcher den Nutzer zurück
zum MainScreen bringt. Um das 3DModell zu rendern verwendet die App das
Plugin Model Viewer ([ 21 ]). Model Viewer erstellt eine WebView und
startet somit einen Server innerhalb der App. Das 3DModell wird in einem
Browser mithilfe von WebGL gerendert und in der App dargestellt. Der
Button rechts unten lädt das Modell im von Google erstellten
modelviewer, auf welchem dieses Plugin basiert. 27

5.7 Probleme 5.7.1 iOS Damit Anwendungen für iOS Systeme kompiliert
werden können, wird eine AppleUmgebung (Macbook, …) benötigt. Da keiner
der Entwickler Zugang zu solch einer Umgebung hat, konnte die
ReleaseVersion der App für iOS nicht getestet werden. 5.7.2
Serverkommunikation In den Anfangsphase der Entwicklung wurde der Server
nur lokal per localhost betrieben. Somit konnte die App nicht mit dem
eigenen Smartphone, sondern nur mit dem in Android Studio enthaltenen
Emulator betrieben werden. Dieser hat keinen Zugriff auf die
normalerweise durch den localhost bereitgestellten Adressen. Android
Studio umgeht dieses Problem, indem localhost über eine andere
Schnittstelle angesprochen werden kann. Die neue Adresse, über welche
die Kommunikation zum localhost möglich ist, muss allerdings zuerst
herausgefunden werden. Der vom Server zurückgesendete Base64kodierte
String bekommt aus unbekannten Gründen zusätzliche Zeichen am Anfang und
Ende hinzu. Diese verhindern, dass der String dekodiert werden kann. Das
daraus resultierende Modell wäre nicht mehr das korrekte, vom Server
gesendete, Modell. Zusätzlich entspricht der String nicht mehr den
Base64Konventionen und sorgt somit für einen Error bei der Dekodierung.
Um dies zu umgehen wird der String am Anfang und Ende gekürzt und somit
alle überschüssigen Symbole entfernt. Zu Beginn war der Server über eine
httpAdresse erreichbar. Ab Android 9 werden allerdings jegliche
Kommunikationsversuche mit einer unverschlüsselten (http) Adresse
standardmäßig blockiert. Somit konnten keine Daten gesendet oder
empfangen werden. In den SettingsDateien von Android lässt sich die
Kommunikation mit unverschlüsselten Adressen aktivieren. Dies ist auch
im Hinblick auf Model Viewer sinnvoll, da das Plugin einen httpServer
erstellt. Das rendern der Modelle wäre somit ohne die Aktivierung der
unverschlüsselten Kommunikation nicht möglich. 28

Zusätzlich wurde dem Server ein Zertifikat hinzugefügt, mit welchem das
Betreiben eines httpsServers möglich ist. 5.7.3 Model Viewer Model
Viewer benutzt den Browser, um die 3DModelle zu ladden und anzuzeigen.
Das Plugin unterstützt dabei aber nur die zwei aktuellsten Versionen der
bekannten Browser (Chrome, Edge, Firefox, Safari, …). Der von Android
Studio bereitgestellte Emulator hat Chrome installiert, davon aber die
Version 83. Die aktuelle Version von Chrome ist allerdings 91. Die auf
dem Emulator verfügbare Version ist somit nicht von Model Viewer
unterstützt. Auf dem Emulator ist kein Play Store vorhanden. Somit kann
die Version von Chrome auch nicht aktualisiert werden. Wird versucht ein
3DModell anzuzeigen, so erscheint nur ein weißer Bildschirm. Dies
resultiert darin, dass alle Tests mit 3DModellen an einem echten Gerät
durchgeführt werden müssen. Zusätzlich wird somit auch ein nicht lokal
laufender Server benötigt. 29

Kapitel 6 Zusammenfassung und Ausblick In dieser Studienarbeit konnte
das Ziel der Generierung eines 3DModells aus einem Bild einer Person,
welche den ZOZOSUIT trägt, realisiert werden. Es werden allerdings nicht
alle Punkte zuverlässig erkannt. Zudem werden zur Generierung des
3DModells eines Menschen bestimmte Punkte am Körper benötigt. Der
ZOZOSUIT hat nur 500 verfügbare Punkte, welche bestenfalls in der Nähe
der benötigten Punkte liegen. Zudem kann ein nicht perfekt sitzender
ZOZOSUIT für starke Verfälschungen sorgen. Das Ergebnis ist ein
3DModell, welches besonders in der Haltung nicht dem ursprünglichen Bild
entspricht. Besonders anfällig sind hierbei die Positionen der Arme und
Beine. Der von ZOZO inc. veröentlichte ZOZOSUIT 2 könnte diese Probleme
lösen. So sind bei diesem die zur Identifizierung benötigten Punkte
besser erkennbar und die Anzahl der auf dem Suit verfügbaren Punkte
wurde auf 20000 erhöht. Durch die erhöhte Punktanzahl und einer besseren
Erkennwahrscheinlichkeit, können die für ein 3DModell relevanten Punkte
zuverlässiger erkannt werden. Zudem soll der ZOZOSUIT 2 passgenauer
sein, was einer Verschiebung des ANzugs entgegenwirkt. Eine
Wiederaufnahme dieser Studienarbeit mit einem ZOZOSUIT 2 wäre somit sehr
interessant. 30

Literatur [1] Forbes: ZOZO inc. URL: https : / / www . forbes . com /
companies / zozo/ (besucht am 13.06.2021). [2] ZOZO history. URL: https
: / / corp . zozo . com / en / about / history/ (besucht am 13.06.2021).
[3] Bild: ZOZOSUIT. URL: https : / / 8900km . de / wp - content /
uploads / 2018 / 10 / zozosuit . jpg (besucht am 13.06.2021). [4]
Aktienkurs: ZOZO inc. URL: https : / / www . boersennews . de / markt /
aktien / detail / jp3399310006/ (besucht am 13.06.2021). [5] QUARTZ:
ZOZO promised too much. URL: https : / / qz . com / quartzy / 1486352 /
zozos - zozosuit - for - custom - clothes - is - looking - like - a -
bust/ (besucht am 13.06.2021). [6] Bild: ZOZOSUIT 2. URL: https : / /
d31ex0fa3i203z . cloudfront . net / assets / global / measurement -
technology / zozosuit2 _ 1 . png (besucht am 13.06.2021). [7] Bild:
ZOZOSUIT 2. URL: https : / / encrypted - tbn0 . gstatic . com / images ?
q = tbn : ANd9GcTk8maq2eZk9LgK66Yi - 2I77YN6cjJno9 _
cieOhnM0znfVwv7FTu0gG0vp - GcGui3zue _ s & usqp = CAU (besucht am
13.06.2021). [8] ZOZOSUIT 2. URL: https : / / corp . zozo . com / en /
measurement - technology/ (besucht am 13.06.2021). [9]
Marktforschung.de, EITO: Smartphonenutzung. URL: https : / / www .
marktforschung . de / aktuelles / marktforschung / acht - von - zehn -
menschen - in - deutschland - nutzen - ein - smartphone/ (besucht am
12.08.2020). [10] Kantarworldpanel.com, Smartphone OS Market Share. URL:
https : / / www . kantarworldpanel . com / global / smartphone - os -
market - share/ (besucht am 13.06.2021). 31

[11] Developer.apple.com, Abschluss und Aktivierung. URL: https : / /
developer . apple . com / de / support / purchase - activation/ (besucht
am 04.09.2020). [12] Play.google.com, Google Play Console. URL: https :
/ / play . google . com / apps / publish / signup/ (besucht am
06.09.2020). [13] Medium.com, React Native vs iOS/Android Native: what
is the best choice for mobile development today? URL: https : / / medium
. com / @smartym . pro / react - native - vs - ios - android - native -
what - is - the - best - choice - for - mobile - development - today -
67cde42fc8bc (besucht am 05.09.2020). [14] Blog.logrocket.com, Flutter
vs. React Native vs. Xamarin. URL: https : / / blog . logrocket . com /
flutter - vs - react - native - vs - xamarin/ (besucht am 05.09.2020).
[15] Insights.stackoverflow.com, Most loved dreaded and wanted. URL:
https : / / insights . stackoverflow . com / survey / 2019 # most -
loved - dreaded - and - wanted (besucht am 05.09.2020). [16] Flutter
Dokumentation. URL: https : / / flutter . dev / docs (besucht am
13.06.2021). [17] Khanh Ha. SMPL Human Model Introduction. 2018. URL:
https : / / khanhha . github . io / posts / SMPL - model - introduction/
(besucht am 13.06.2021). [18] Wikipedia. Axis–angle representation —
Wikipedia, The Free Encyclopedia. 2021. URL: http : / / en . wikipedia .
org / w / index . php ? title = Axis % 5C % E2 % 5C % 80 % 5C % 93angle
% 5C % 20representation & oldid = 1022906751 (besucht am 13.06.2021).
[19] Ahmed A A Osman, Timo Bolkart und Michael J. Black. „ STAR: A
Sparse Trained Articulated Human Body Regressor“. In: European
Conference on Computer Vision (ECCV). 2020, S. 598– 613. URL: https : /
/ star . is . tue . mpg . de . [20] Base64. URL: https : / / de .
wikipedia . org / wiki / Base64 (besucht am 13.06.2021). [21] Model
Viewer. URL: https : / / pub . dev / packages / model _ viewer (besucht
am 13.06.2021). 32
